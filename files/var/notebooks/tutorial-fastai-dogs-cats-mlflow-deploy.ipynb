{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effortless models deployment with Mlflow\n",
    "\n",
    "**Author:** [Facundo Santiago (post link)](https://santiagof.medium.com/effortless-models-deployment-with-mlflow-customizing-inference-e880cd1c9bdd)<br>\n",
    "**Editor:** [neu.ro](https://neu.ro)<br>\n",
    "**Date created:** 2022/03/16<br>\n",
    "**Last modified:** 2022/08/23<br>\n",
    "\n",
    "**Description:** Training an image classifier from scratch on the Kaggle Cats vs Dogs dataset, storing model in MLFLow and deploying it to Neu.ro platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous example, I showed how, by adopting MLFlow for logging models in your experiments, you can gain free deployment options in a variety of targets. However, one of the limitation presented with that is that you have to get along with the default way inference is proposed for the model flavor you are using.\n",
    "\n",
    "For instance, if you are using fastai, then models will return the probabilities returned by the model directly. But what about if you have to do something different with those outputs? What about if you have to do some preprocessing before submitting the data to the model? In this example, I will show how can log the model using the `pyfunc` flavor to customize how inference is run. Particularly, we will change the output values for the model to return 2 columns: `class`, meaning the class index number (0 or 1), and `label`, meaning the label associated with the given class index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving the problem\n",
    "\n",
    "Let's start by getting some undestanding of the problem. This is what we know:\n",
    "\n",
    "<ul>\n",
    "    <li><b>Problem type:</b> Classification</li>\n",
    "    <li><b>Number of classes:</b> 2 (cats, dogs)</li>\n",
    "    <li><b>Input:</b> Images (25.000 — 50% cats, 50% dogs)</li>\n",
    "</ul>\n",
    "\n",
    "The dataset is completely balanced. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing fast.ai\n",
    "\n",
    "We are introducing here a framework called fast.ai (https://www.fast.ai/), a framework based on PyTorch with some handy operations already implemented to speed up problem solving quickly. To use fast.ai, we need to import 2 libraries: fastai and torch. fast.ai also has the named dataset already uploaded as part of the framework, which makes pretty convenient to work with it.\n",
    "\n",
    "> Since fast.ai is a pretty unstable API (it changes very frequently), we pin a specific version: `fastai==2.4.1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"> <b>IMPORTANT</b> This notebook is designed to run on the Neu.ro platform, within the Jupyter server running as Application. MLFlow Application should be started beforehand and integrated with this Jupyter server App."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's install FastAI framework, since it is not included to the base image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install fastai==2.4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1645748700893
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import fastai\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Since this is a computer vision problem, let's load some of the specific classes in FastAI for Computer Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1645748702043
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastai.vision.data import ImageDataLoaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First things first, let's download and unzip the dataset. Please take into consideration that this dataset is a bit big. Notice path `/var/storage` is the place, where your user's storage home directory is mounted to persist changes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1645748702428
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "path = untar_data(URLs.DOGS, dest=\"/var/storage/.fastai\")\n",
    "image_files = get_image_files(path)\n",
    "print('Data located at:', path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "As images are unzipped in a folder, we need to create a dataset to use for training and testing. `fast.ai` has a very simple way to do that. The method `ImageDataLoader.from_folder` creates a dataset of images located in a folder. The folder itself has a pretty peculiar structure (imagenet format) where the data is already divided in trian/test and labels are inferred from the folder containing the image (folder cats contain `cats` and folder dogs contains `dogs`.\n",
    "\n",
    "`batch_tfms` indicates which image transformations to apply in batches to all the images, while `item_tfms` indicate which transformations will be applied individually to each image. This is useful to construct transformation pipelines right into the data loader. The ds_tfms() method quickly gets a set of random transforms that have proved to work well in a wide range of tasks in computer vision, including a random flip is applied with probability 0.5, a random rotation, a random zoom, a random lightning and contrast change and a random symmetric warp.\n",
    "\n",
    "Finally, the function normalize creates a normalize/denormalize func using an specific mean and std. In this case, those parameters are taken from the imagenet dataset, using the values imagenet_stats which are means = [0.485, 0.456, 0.406] and stds = [0.229, 0.224, 0.225]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1645748704926
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "data_loader = ImageDataLoaders.from_folder(path, item_tfms=Resize(224), batch_tfms=Normalize.from_stats(*imagenet_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1645748706133
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_loader.train.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Creating a classifier based on ResNet34\n",
    "\n",
    "#### Starting the mlflow experiment\n",
    "\n",
    "Before starting, let's create a new experiemnt in Mlflow so we can track all the experimentation on it using Mlflow Tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "experiment_id = mlflow.set_experiment(\"mlflow-fastai-cats-vs-dogs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Let's start the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "mlflow.start_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** In general, we would run the training code in a `with` block using `with mlflow.start_run()`. This will ensure that everything in the with block is part of the run and hence mlflow will be able to track the time it takes to run the experiment. Since we are running this interactively in a notebook, we have to run the `start_run()` method at the beginning and `end_run()` at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn on `Autolog()`. This will enable MLFlow go gather all training metrics automatically (checkout [MLFlow docs](https://www.mlflow.org/docs/latest/python_api/mlflow.fastai.html#mlflow.fastai.autolog) for more information). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.fastai.autolog(log_models=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Why `log_models` is set to `false`?** In this example, we are going to change the way MLFlow runs inference for the model. If we tell MLFlow to automatically log the model, then we won't have a chance to change the default behavior. By disabling auto log of models, metrics and parameters will continue to be automatically tracked but models needs to be log manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Designing a CNN\n",
    "Once our dataset is ready, it's time to create our neural network. CNN represents a very convenient way to solve Computer Vision problems, specially when combined with transfer learning. We use transfer learning with a pretrained image classification models to extract visual features. The idea behind it is that the representations learned for task A (typically a high-level task) are applied to task B (typically a lower-level task) as for the degree of success at task B indicates how much the task A model has learned about task B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1645720575464
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "learn = cnn_learner(data_loader, models.resnet34, metrics=accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then it's time to train. When using transfer learning, the training process is a bit different like in a normal network. In the processes we take a pre-trained model and “fine-tuning” the model with your our own dataset. The idea is that this pre-trained model will act as a feature extractor. You will remove the last layer of the network and replace it with your own classifier. You then freeze the weights of all the other layers and train the network normally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1645721221345
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "suggested_lr = learn.lr_find()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm using here the method `learn.lr_find()`. What this method does behind the scenes is running for few epochs to find out a good learning rate, where it trains from some low learning rate and increase the learning rate after each mini-batch till the loss value starts to explode. This single run provides valuable information on how well the network can be trained over a range of learning rates and what is the maximum learning rate. This is based on a paper https://arxiv.org/abs/1506.01186 which is a really good reading by the way. In Cyclical learning rates (CLR) one specifies minimum and maximum learning rate boundaries and a stepsize. The stepsize is the number of iterations (or epochs) used for each step and a cycle consists of two such steps – one in which the learning rate linearly increases from the minimum to the maximum and the other in which it linearly decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then see which is the suggested learning rate by using the property `valley`. Let's use that to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1645728269408
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "learn.fine_tune(1, suggested_lr.valley)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For simplicity, I'm only training for 1 epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the model works with an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1645748852651
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from fastai.vision.core import load_image\n",
    "\n",
    "sample_img = load_image(image_files[1])\n",
    "sample_img_arr = np.array(sample_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Resizing the image is not required, as the model can do that in its trainsformation's pipeline. The reason why I do this is a bit bellow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Running the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1645748253274
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "dl_model = learn.dls.test_dl([sample_img_arr])\n",
    "real_preds, _ = learn.get_preds(dl=dl_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(real_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain the classes rather than the probabilities, we can do something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_idxs = real_preds.argmax(axis=1)\n",
    "print(class_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = [(c.numpy(), learn.dls.vocab[c]) for c in class_idxs]\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persisting the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is trained, it's time to save the work. \n",
    "\n",
    "> **Note:** An important distinction here, `learn.save` will save the model itself in the `PyTorch` format, while the method `learn.export` will save both the model along with all the data transformations applied. This is important since at inference time our model expects to recive images that has been altered the same way the previous data loaded did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1645745519970
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "saved_model = \"/tmp/model.fastai\"\n",
    "learn.export(saved_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model will take batches of images and will return the class of each (in our case either cat or dog). This means that our inputs will be tensors of shape `(IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS)`. Since the model expects batches of images, the right input shape is `(BATCH_SIZE, IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS)`.\n",
    "\n",
    "For our output, we want to return both the class index and the class label. Then, our output signature will have a shapre `(-1, 2)` but with an specific struncture: two columns: `class` and `label`.\n",
    "\n",
    "The schema then will be as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import Schema, TensorSpec, ColSpec\n",
    "from mlflow.types import DataType\n",
    "\n",
    "input_schema = Schema([\n",
    "  TensorSpec(np.dtype(np.uint8), (-1, -1, -1, 3)),\n",
    "])\n",
    "output_schema = Schema([\n",
    "  ColSpec(DataType.integer, \"class\"),\n",
    "  ColSpec(DataType.string, \"label\"),\n",
    "])\n",
    "signature = ModelSignature(inputs=input_schema, outputs=output_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some notes:\n",
    "\n",
    "- **input_schema**: Our model can handle variable image sizes, since it has a transformation that resizes the image in the process (the `Resize(224)` transformation). Then, we can indicate a variable input size using -1 in `height` and `width`. The same applies to batch size, since we can handle variable sizes.\n",
    "\n",
    "- **output_schema**: Our model will return two columns. We are not using tensor specification cause we want to be explicit about what are the things we are returning, so we can see we are actually indicating which is the name of the columns we return."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the model in the Mlflow format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "To save the model using Mlflow, we can call the function `mlflow.fastai.log_model`. However, this function will run the model and return its output directly, without any further processing. We can change this behaviour by using the `pyfunc` flavor:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the pyfunc flavor in two ways:\n",
    "\n",
    "- The simplest way is to provide a custom model loader module.\n",
    "- Create a custom flavor. This one is a bit more complex.\n",
    "\n",
    "**In this example we will use the first one**. To use `pyfunc` flavor with a custom model loader, we are asked to implement two things:\n",
    "\n",
    "- a class that acts as a model wrapper. This class has to have a method `predict()`.\n",
    "- a model loader function called `_load_pyfunc(path)` where path is the path to the models' artifact and that returns an instance of the previously mentioned class.\n",
    "\n",
    "Let's have a lookg at how we can achieve this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's create the model class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _FastaiClassifierModelWrapper:\n",
    "    def __init__(self, learner):\n",
    "        self.learner = learner\n",
    "\n",
    "    def predict(self, data):\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        \n",
    "        dl = self.learner.dls.test_dl(data)\n",
    "        preds, _ = self.learner.get_preds(dl=dl)\n",
    "        \n",
    "        # converting probabilities to classes\n",
    "        class_idxs = preds.argmax(axis=1)\n",
    "        results = [(c.numpy(), self.learner.dls.vocab[c]) for c in class_idxs]\n",
    "        \n",
    "        return pd.DataFrame(results, columns=[\"class\", \"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simple class contains:\n",
    "\n",
    "- A constructor that recieves an instance of a `fastai.learner` model.\n",
    "- The predict function we are required to implement. This function recieves a data an returns the predictions in a dataframe with columns named `class` and `label`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to provide a way to load this model. Again, this is done by implementing the function `_load_pyfunc()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_pyfunc(path):\n",
    "    import os\n",
    "    from fastai.learner import load_learner\n",
    "    \n",
    "    learn = load_learner(os.path.abspath(path))\n",
    "    \n",
    "    return _FastaiClassifierModelWrapper(learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all! Now let's place this inside of a module so we can use it later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile fastai_classifier_module.py\n",
    "\n",
    "class _FastaiClassifierModelWrapper:\n",
    "    def __init__(self, learner):\n",
    "        self.learner = learner\n",
    "\n",
    "    def predict(self, data):\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        \n",
    "        dl = self.learner.dls.test_dl(data)\n",
    "        preds, _ = self.learner.get_preds(dl=dl)\n",
    "        \n",
    "        # converting probabilities to classes\n",
    "        class_idxs = preds.argmax(axis=1)\n",
    "        results = [(c.numpy(), self.learner.dls.vocab[c]) for c in class_idxs]\n",
    "        \n",
    "        return pd.DataFrame(results, columns=[\"class\", \"label\"])\n",
    "\n",
    "def _load_pyfunc(path):\n",
    "    import os\n",
    "    from fastai.learner import load_learner\n",
    "    \n",
    "    learn = load_learner(os.path.abspath(path))\n",
    "    \n",
    "    return _FastaiClassifierModelWrapper(learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to log the model in MLFlow. We also include `fastai` version as extra pip requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info = mlflow.pyfunc.log_model(\n",
    "    \"classifier\", \n",
    "    data_path=saved_model, \n",
    "    code_path=[\"./fastai_classifier_module.py\"], \n",
    "    loader_module=\"fastai_classifier_module\", \n",
    "    registered_model_name=\"cats_vs_dogs\", \n",
    "    signature=signature,\n",
    "    extra_pip_requirements=[\"fastai==2.4.1\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's unpack how this instruction works:\n",
    "\n",
    "- **classifier** is the artifacts path we will use. Same as before, we are using the path `classifier`.\n",
    "- **data_path** is the model artifact. When we used `mlflow.fastai.log_model`, MLFlow automatically saved our model to disk to then include it inside the MLModel package. However, when we use `pyfunc`, this doesn't happen automatically. We have full controll of it so we have to persist the model to disk. We did that before, and we saved the path where the model was persisted in a variable called `saved_model`. \n",
    "- **code_path** is where the code for the `pyfunc` logic is located. We placed all the logic inside of the file `fastai_classifier_module.py`. So we pass that file path.\n",
    "- **loader_module** is the name of the module where the `_load_pyfunc` function is defined. In our case, that function is inside the file `fastai_classifier_module.py`. Remember that in Python, files are modules and the name of the associated module is the name of the file, so the name of the module here is `fastai_classifier_module`. If you are thinking \"this looks redundant\", it worth to mention that code_path can be the path to a directory, containing multiple code files. MLFLow will snapshot all the files in that directory, so it needs to know which of all those files (in our case is just one) is the one it has to load first.\n",
    "- **registered_model_name** is the name of a model in MLFlow model registry, to which this particular model version should be assigned.\n",
    "- **signature** is the description of model inputs and outputs used during the inference.\n",
    "- **extra_pip_requirements** is a list of Python requirements needed to run the model. Usually, MLFlow infers this automatically, but when it fails (or you have some extra requirements), this becomes handy, for instance, to pin some package to a specific version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ending the experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we were running this experiment interactively in this notebook, we have to end it using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying your model using mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see how we can deploy the model using Mlflow. Before doing that, it is always good to check that our model was persisted correctly and that it can be loaded. This will save us some time later in case something wrong happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's grab the URI of the model we just registered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_model_uri = model_info.model_uri\n",
    "print(serving_model_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's the URI of the model inside the run (which we can totally deploy if we want to). However, I'm interested in deployed the model that ended registered in the Registry. This model will have a URI with the form `models:/cats_vs_dogs/latest`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_model_uri = 'models:/cats_vs_dogs/latest'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `latest` will resolve the latest version of the given model. If you want an specific version of the model, we can use a syntax like `models:/cats_vs_dogs/1` for version `1` for instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the model just logged in MLFLow using the pyfunc flavor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's try to load the model using the `pyfunc` flavor into this notebook. We can use this method to check that the model can be loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1645748721219
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "mlflow_model = mlflow.pyfunc.load_model(serving_model_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a simple batch to test it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_batch = sample_img_arr.reshape(1, sample_img.height, sample_img.width,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1645748879056
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "mlflow_model.predict(sample_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note how we use here the method `predict` to run the predictions, but now we get classes instead of probabilities. Compare this with the way we used to run the model before in the section [Testing the trained model](#Testing-the-trained-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the model in a local server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run the model in an inference server locally in our local compute. Again, with this we can check that our deployment strategy will work. \n",
    "\n",
    "To do so, execute this in a dedicated Jupyter server console:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "mlflow models serve -m models:/cats_vs_dogs/latest\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a sample request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"sample.json\", \"w\") as f:\n",
    "    f.write(json.dumps(\n",
    "        {\n",
    "            \"instances\": sample_batch.tolist()\n",
    "        }\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sending the request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat -A sample.json | curl http://127.0.0.1:5000/invocations \\\n",
    "                        --request POST \\\n",
    "                        --header 'Content-Type: application/json' \\\n",
    "                        --data-binary @-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the model to Neu.ro platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLflow is integrated with several Machine Learning platforms, including Neu.ro MLOps platform. We can deploy models created with MLFlow without changing any single implementation about them. They can be deployed using [Job Deployment Application](https://github.com/neuro-inc/mlops-job-deploy-app).\n",
    "\n",
    "Open platform Web inferface, navigate to Applications Dashboard and start Job Deployment Application attached to the MLFlow instance you used with this Jupyter instance.\n",
    "\n",
    "When the Application is started, create new deployment for previously registered model version using MLFlow as a target server, and disable authentication (for tests purposes). Use `mlflow` or `base` images to serve the model.\n",
    "\n",
    "When the model server completes environment creation and model startup, use it's Endpoint URL to query the model with the same method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat -A sample.json | curl <endpoint-url>/invocations \\\n",
    "                        --request POST \\\n",
    "                        --header 'Content-Type: application/json' \\\n",
    "                        --data-binary @-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "When you are done with the tutorial, terminate everything you created for it: deployed inference server, Job Deployment Application, Jupyter, and MLFlow servers."
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "fastai"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 ('triton-mlflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "efc707786b5bf2d11ded046d2ecc6efc964a7292a503edb244036761df97e74d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
